[["index.html", "Curley Lab Code Tutorials Chapter 1 Introduction", " Curley Lab Code Tutorials James Curley 2021-09-09 Chapter 1 Introduction This set of pages is intended for students in the Curley Lab, Department of Psychology, University of Texas at Austin. It contains code examples that might be useful for learning some of the methods that we use in our lab. Others may also find it useful - but it is written with my lab members in mind, so apologies if some things are left unexplained. "],["analyzing-social-hierarchy-data.html", "Chapter 2 Analyzing Social Hierarchy Data 2.1 Overview 2.2 Raw Data 2.3 Data Cleanup 2.4 Data Analysis 2.5 Basic hierarchy Measures 2.6 Individual Ranking Measures 2.7 Plotting Sociomatrices 2.8 Network Certainty 2.9 Temporal Based Methods 2.10 Summary", " Chapter 2 Analyzing Social Hierarchy Data 2.1 Overview This is a brief introduction into how my lab analyzes social hierarchy data. It is primarily for my students to use as a guide, but much of it is probably useful for anybody that has any type of win-loss data. We will use an example raw data file from our lab and various R packages to analyze the data. We will heavily use my compete R package for analyzing competitive social interactions. The package contains some functions for transitioning data from edgelists of winner-losers to raw frequency win-lose sociomatrices to binary sociomatrices. The package also contains several functions for calculating particular hierarchy metrics. Additional R packages for calculating other metrics that we will use are detailed below. We will also source some code Ive stored on GitHub (compete_extra.R) that contains several functions used here. 2.2 Raw Data We collect data on which animals win and lose during dyadic agonistic interactions that occur continuously within a social group. Typically we study groups of 12 individuals - each individual being randomly assigned the numbers 1-12 to identify them. Wins and losses (and ties) are collected in real time by observers who upload to a Google Survey data sheet. One option for retrieving the raw data would be to automatically download the data from Google Survey itself using an R package like googlesheets4. However, for now the simplest method is to download the raw data file from Google and store it somewhere. I have done this for an example file and stored it on GitHub. Note to students: make sure you download the file as a csv file not an xls file. The timestamp column should have seconds in it - if you save as an xls file it may get rid of the seconds and they will all appear as 00. For this introduction, we will use the data stored here: df &lt;- read.csv(&quot;https://gist.githubusercontent.com/jalapic/97d05d598e9d4d96be5686e87b5bd452/raw/fe60da1542527d159e105c5560f250886f54a2dc/mousedata.csv&quot;, stringsAsFactors = F) head(df) ## Timestamp Actor Behavior Recipient Location Observer Notes ## 1 10/14/2014 11:57:16 Start Start Start Start CW &lt;NA&gt; ## 2 10/14/2014 12:03:10 6 Mounting 10 NB4 CW &lt;NA&gt; ## 3 10/14/2014 12:04:16 6 Fighting 5 NB5 CW &lt;NA&gt; ## 4 10/14/2014 12:19:27 3 Fighting 4 ML CW &lt;NA&gt; ## 5 10/14/2014 12:28:05 4 Subordinate 10 LL CW &lt;NA&gt; ## 6 10/14/2014 12:30:49 4 Fighting 2 NB1 CW &lt;NA&gt; 2.3 Data Cleanup The first thing to do with the raw data is to clean up mistakes made by observers and to check for other mistakes. These will generally be put in the notes column, but there are others to check for. The main issues are to do with animals being misidentified or observers forgetting to enter a start/end time or adding multiple start/end times. Most notes in this example dataset are blank - but you can see those that are there by doing the following to remove NA: df$Notes[!is.na(df$Notes)] ## [1] &quot;long fight, it wasn&#39;t clear who started it, neither gave in&quot; ## [2] &quot;chased from mid left to upper left, some biting of the tsail&quot; ## [3] &quot;chase from UR to UL&quot; ## [4] &quot;UR =&gt; UL&quot; ## [5] &quot;unrelated to previous fight -- abt a min later&quot; ## [6] &quot;UL =&gt; UR&quot; ## [7] &quot;late bc extractim&quot; ## [8] &quot;**last note was supposed to say late bc extracting rna with rahia&quot; ## [9] &quot;another incidence, not a double record&quot; ## [10] &quot;another incidence, not a double record&quot; ## [11] &quot;in general, the mice were much less active during the second hour&quot; ## [12] &quot;in general, the mice were much less active during the second hour&quot; ## [13] &quot;happened in the tube between lower left and nest box 2&quot; ## [14] &quot;***weird bc 3 is notma&quot; ## [15] &quot;comment a few back was supposed to say weird bc 3 is normally dominant, but im sure it was 3&quot; ## [16] &quot;contextual aggression?&quot; ## [17] &quot;ul down to nb5&quot; ## [18] &quot;at the same time as 6 chased 10&quot; ## [19] &quot;couldn&#39;t tell who won&quot; ## [20] &quot;6 attacked first then 4 wins the fight&quot; ## [21] &quot;prolonged intense fight tied, though 6 fleed at last&quot; ## [22] &quot;prolonged intense fight tied, though 6 fleed at last&quot; ## [23] &quot;internet disruption at 12 45pm&quot; ## [24] &quot;8 has distinguished size of testes&quot; The only comment here that needs double checking is the one where the observer couldnt determine who won. That contest should be scored as a tie. We can check by finding the row number and searching for it. which(df$Notes==&quot;couldn&#39;t tell who won&quot;) ## [1] 951 df[951,] ## Timestamp Actor Behavior Recipient Location Observer ## 951 11/3/2014 15:44:34 2, 9 Fighting 2, 9 NB5 BN ## Notes ## 951 couldn&#39;t tell who won As can be seen, its a tie between 2 &amp; 9. 2.3.1 Time Formats Next, its useful to add a day column and a time column. The following assumes: that the first day of observations was the first day of housing (it almost always is). that there were no changes in daylight savings or light cycle that the google survey was set up in EST. that the observations all took place within the same calendar year. If any of the above are not true, the following code needs to be adjusted. If they are all true well first convert the Google Survey timestamp to Rs Date-Time format and extract the day and time. We use the lubridate package to extract hours and days. We also make sure the Date-Time format we use is POSIXct as POSIXlt uses too much memory. The first day of observations is day 1. The first hour of observation each day is at 12pm when the lights change from white to red (the animals become more active in red light/dark phase). df$Timestamp &lt;- as.POSIXct(strptime(df$Timestamp,&#39;%m/%d/%Y %H:%M:%S&#39;)) df$day &lt;- lubridate::yday(df$Timestamp) - min(lubridate::yday(df$Timestamp)) + 1 df$zhour &lt;- lubridate::hour(df$Timestamp)-11 head(df) ## Timestamp Actor Behavior Recipient Location Observer Notes day ## 1 2014-10-14 11:57:16 Start Start Start Start CW &lt;NA&gt; 1 ## 2 2014-10-14 12:03:10 6 Mounting 10 NB4 CW &lt;NA&gt; 1 ## 3 2014-10-14 12:04:16 6 Fighting 5 NB5 CW &lt;NA&gt; 1 ## 4 2014-10-14 12:19:27 3 Fighting 4 ML CW &lt;NA&gt; 1 ## 5 2014-10-14 12:28:05 4 Subordinate 10 LL CW &lt;NA&gt; 1 ## 6 2014-10-14 12:30:49 4 Fighting 2 NB1 CW &lt;NA&gt; 1 ## zhour ## 1 0 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 tail(df) ## Timestamp Actor Behavior Recipient Location Observer ## 1054 2014-11-04 13:51:49 4 Fighting, Chasing 6 LL WL ## 1055 2014-11-04 13:52:49 4 Chasing 6 UL WL ## 1056 2014-11-04 13:53:42 4 Chasing 10 UL WL ## 1057 2014-11-04 13:55:10 6 Chasing 12 LL WL ## 1058 2014-11-04 13:56:48 4 Chasing 10 UL WL ## 1059 2014-11-04 14:00:48 End End End End WL ## Notes day zhour ## 1054 &lt;NA&gt; 22 2 ## 1055 &lt;NA&gt; 22 2 ## 1056 &lt;NA&gt; 22 2 ## 1057 &lt;NA&gt; 22 2 ## 1058 &lt;NA&gt; 22 2 ## 1059 &lt;NA&gt; 22 3 unique(df$day) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 21 22 Notice that there are no observations for day=20 - this will be relevant later on when we plot data by day. 2.3.2 Actor/Recipients Next we will look at the Actor and Recipient variables. unique(df$Actor) ## [1] &quot;Start&quot; &quot;6&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;1&quot; &quot;9&quot; &quot;2, 4&quot; ## [9] &quot;End&quot; &quot;12&quot; &quot;2&quot; &quot;7&quot; &quot;11&quot; &quot;1, 2&quot; &quot;10, 11&quot; &quot;8&quot; ## [17] &quot;10&quot; &quot;2, 9&quot; &quot;2, 11&quot; &quot;7, 11&quot; &quot;4, 6&quot; &quot;3, 6&quot; unique(df$Recipient) ## [1] &quot;Start&quot; &quot;10&quot; &quot;5&quot; &quot;4&quot; &quot;2&quot; &quot;1&quot; ## [7] &quot;11&quot; &quot;8&quot; &quot;2, 4&quot; &quot;7&quot; &quot;3&quot; &quot;6&quot; ## [13] &quot;End&quot; &quot;9&quot; &quot;7, 10&quot; &quot;1, 2&quot; &quot;10, 11&quot; &quot;12&quot; ## [19] &quot;1, 9&quot; &quot;7, 8&quot; &quot;7, 12&quot; &quot;2, 6&quot; &quot;8, 10&quot; &quot;3, 7&quot; ## [25] &quot;11, 12&quot; &quot;2, 9&quot; &quot;2, 7&quot; &quot;2, 8, 10&quot; &quot;1, 7, 12&quot; &quot;3, 6&quot; ## [31] &quot;6, 8&quot; &quot;2, 11&quot; First of all, we can remove the Start and End rows. These indicate when an observer starts and finishes their set observation. We need these when counting rates of behavior per hour, but we wont do that in this example. df &lt;- df[df$Actor!=&quot;Start&quot;,] df &lt;- df[df$Actor!=&quot;End&quot;,] The next thing to deal with is that some rows have multiple values in the Actor or Recipient columns. This can be either: two individuals tie during a contest (then both Actor and Recipient will have same two animals in the entry) one Actor beats more than one Recipient simultaneously one Recipient is beaten by more than one Actor simultaneously (much less common) To simplify this process, I have stored a function - expandrows on GitHub that we can source. With time, Ill add this function to my CurleyLab R package to make it easily available. To use it, you must have splitstackshape and data.table installed. The former is a great package for easy management of google survey type data. This function also adds a column score with a 1 indicating a clear win for the Actor vs the Recipient, and a 0.5 indicating a tie. source(&quot;https://gist.githubusercontent.com/jalapic/6ca3ece44bdcdc522bb735f183aa0ca0/raw/1a07f469eff08117121b6cbebcd22fb7569e3ee8/compete_extra.R&quot;) df1&lt;-expandrows(df) head(df1) ## Timestamp Actor Behavior Recipient Location Observer Notes day ## 1: 2014-10-14 12:03:10 6 Mounting 10 NB4 CW &lt;NA&gt; 1 ## 2: 2014-10-14 12:04:16 6 Fighting 5 NB5 CW &lt;NA&gt; 1 ## 3: 2014-10-14 12:19:27 3 Fighting 4 ML CW &lt;NA&gt; 1 ## 4: 2014-10-14 12:28:05 4 Subordinate 10 LL CW &lt;NA&gt; 1 ## 5: 2014-10-14 12:30:49 4 Fighting 2 NB1 CW &lt;NA&gt; 1 ## 6: 2014-10-14 12:34:39 4 Fighting 2 NB5 CW &lt;NA&gt; 1 ## zhour score ## 1: 1 1 ## 2: 1 1 ## 3: 1 1 ## 4: 1 1 ## 5: 1 1 ## 6: 1 1 nrow(df1) ## [1] 1031 table(df1$Actor) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 ## 20 10 136 480 7 136 150 20 5 3 51 13 table(df1$Recipient) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 ## 66 94 111 9 37 119 131 121 93 96 89 65 table(df1$score) ## ## 0.5 1 ## 6 1025 In total we have 1031 agonistic interactions of which only 6 are ties. Having got our data cleaned up, we can quickly look at a preliminary raw sociomatrix: xtabs(~ Actor + Recipient, df1) ## Recipient ## Actor 1 2 3 4 5 6 7 8 9 10 11 12 ## 1 0 4 1 1 2 3 0 2 6 0 0 1 ## 2 0 0 1 1 0 0 2 2 2 0 2 0 ## 3 9 16 0 2 8 23 45 13 6 9 0 5 ## 4 21 40 79 0 16 53 76 43 38 28 64 22 ## 5 2 0 0 1 0 3 0 0 1 0 0 0 ## 6 11 13 9 2 3 0 4 39 8 22 4 21 ## 7 5 16 1 0 4 33 0 17 22 32 11 9 ## 8 4 1 11 0 0 0 1 0 1 0 2 0 ## 9 0 0 0 1 0 0 0 0 0 0 3 1 ## 10 1 0 0 0 0 0 0 0 0 0 1 1 ## 11 13 3 8 0 1 3 2 2 9 5 0 5 ## 12 0 1 1 1 3 1 1 3 0 0 2 0 2.4 Data Analysis Once our data is in this clean format we can proceed with the basic data analysis. First of all we will consider all behaviors together - i.e. we wont subset or weight by fighting, chasing, mounting or subordinate behaviors. We may want to do this for more fine-grained analysis, but not for this example. Also, we will consider all data collected over all days together to start with. We will use the compete package to create sociomatrices and calculate several metrics. # devtools::install_github(&#39;jalapic/compete&#39;) library(compete) 2.4.1 Create Sociomatrices First we only need the winner and loser variables. Also, in this basic analysis, we will exclude ties. We could consider ties to be a 0.5 win, but given their low prevalence, it does not affect our results to exclude here. (Note the get_wl_matrix and get_di_matrix functions in compete can also automatically remove ties). Also, because df1 is actually a data.table (produced by the expandrows function), we need to use data.table style indexing. wldf &lt;- df1[score==1][, c(2,4), with = FALSE] #data.table indexing head(wldf) ## Actor Recipient ## 1: 6 10 ## 2: 6 5 ## 3: 3 4 ## 4: 4 10 ## 5: 4 2 ## 6: 4 2 The get_wl_matrix creates a raw frequency sociomatrix of wins and losses. This is similar to the table above. Here, e.g. animal 6 won 13 times against animal 2, and animal 7 had 17 wins against animal 8. wlmat &lt;- get_wl_matrix(wldf) wlmat ## Recipient ## Actor 1 10 11 12 2 3 4 5 6 7 8 9 ## 1 0 0 0 1 3 1 1 2 3 0 2 6 ## 10 1 0 0 1 0 0 0 0 0 0 0 0 ## 11 13 5 0 5 3 8 0 1 3 2 2 9 ## 12 0 0 2 0 1 1 1 3 1 1 3 0 ## 2 0 0 2 0 0 1 0 0 0 2 2 1 ## 3 9 9 0 5 16 0 2 8 21 45 13 6 ## 4 21 28 64 22 40 79 0 16 53 76 43 38 ## 5 2 0 0 0 0 0 1 0 3 0 0 1 ## 6 11 22 4 21 13 9 2 3 0 4 39 8 ## 7 5 32 11 9 16 1 0 4 33 0 17 22 ## 8 4 0 2 0 1 11 0 0 0 1 0 1 ## 9 0 0 3 1 0 0 1 0 0 0 0 0 For quick visualization purposes, we can use the org_matrix function. There are three methods of displaying the table - by alphanumeric name (alpha), by total wins (wins) or by Davids Scores (a measure of relative dominance). Using the Davids Scores Methods, it looks a lot clearer that this social group has a hierarchical structure. org_matrix(wlmat, method=&quot;ds&quot;) ## Recipient ## Actor 4 7 3 6 11 10 5 8 1 12 2 9 ## 4 0 76 79 53 64 28 16 43 21 22 40 38 ## 7 0 0 1 33 11 32 4 17 5 9 16 22 ## 3 2 45 0 21 0 9 8 13 9 5 16 6 ## 6 2 4 9 0 4 22 3 39 11 21 13 8 ## 11 0 2 8 3 0 5 1 2 13 5 3 9 ## 10 0 0 0 0 0 0 0 0 1 1 0 0 ## 5 1 0 0 3 0 0 0 0 2 0 0 1 ## 8 0 1 11 0 2 0 0 0 4 0 1 1 ## 1 1 0 1 3 0 0 2 2 0 1 3 6 ## 12 1 1 1 1 2 0 3 3 0 0 1 0 ## 2 0 2 1 0 2 0 0 2 0 0 0 1 ## 9 1 0 0 0 3 0 0 0 0 1 0 0 Another useful matrix to keep is the binarized win-loss matrix. This can be done using the get_di_matrix function. There are many ways in which a raw frequency sociomatrix could be converted to a binary matrix involving how to deal with ties, how to deal with structural zeros (unknown relationships where no observations were made between two individuals), and what criteria to use to choose a clear winner. Here, we will use the simplest measure of assigning a 1 to individuals who win more frequently than the opposing individual and a 0 to losers or if there are ties (e.g. if both animals had 1 win against each other). bimat &lt;- get_di_matrix(wlmat) org_matrix(bimat, method=&quot;ds&quot;) ## Recipient ## Actor 4 3 7 6 11 10 5 1 8 2 12 9 ## 4 0 1 1 1 1 1 1 1 1 1 1 1 ## 3 0 0 1 1 0 1 1 1 1 1 1 1 ## 7 0 0 0 1 1 1 1 1 1 1 1 1 ## 6 0 0 0 0 1 1 0 1 1 1 1 1 ## 11 0 1 0 0 0 1 1 1 0 1 1 1 ## 10 0 0 0 0 0 0 0 1 0 0 1 0 ## 5 0 0 0 0 0 0 0 0 0 0 0 1 ## 1 0 0 0 0 0 0 0 0 0 1 1 1 ## 8 0 0 0 0 0 0 0 1 0 0 0 1 ## 2 0 0 0 0 0 0 0 0 1 0 0 1 ## 12 0 0 0 0 0 0 1 0 1 1 0 0 ## 9 0 0 0 0 0 0 0 0 0 0 1 0 2.5 Basic hierarchy Measures 2.5.1 Descriptives From the above matrices we can calculate a number of descriptive statistics. The rshps function gives us the total relationships in the group, the total number of unknown relationships (i.e. each animal recorded 0 wins against each other), the number of relationships that are tied (i.e. no clear winner), the number of twoways relationships (where both animals recorded at least one win) and the number of oneways relationships (where only one animal recorded a win). rshps(wlmat) ## $total ## [1] 66 ## ## $unknowns ## [1] 6 ## ## $ties ## [1] 3 ## ## $twoways ## [1] 25 ## ## $oneways ## [1] 32 2.5.2 Directional Consistency The Directional Consistency of the sociomatrix - 0 meaning no directional consistency and 1 indicating that all contests are won by more dominant individuals over more subordinate individuals. The skew-symmetry index determines if there is asymmetry in interactions in a sociomatrix. 0 indicates complete reciprocity whereas 0.5 indicates complete unidirectionality. The dc_test function will run the statistical tests suggested by Leiva et al. 2009 to ascertain if the directional consistency and phi values are significant or not. dc_test(wlmat) ## $DC.pvalue ## [1] 1e-04 ## ## $phi.pvalue ## [1] 1e-04 ## ## $mean_phi ## [1] 0.02529858 ## ## $mean_DC ## [1] 0.1286561 ## ## $variance_phi ## [,1] ## [1,] 2.548583e-05 ## ## $variance_DC ## [,1] ## [1,] 0.0002081977 ## ## $DC ## [1] 0.8712195 ## ## $phi ## [1] 0.4689508 For quick access to the DC and phi values, the following functions can be run: dci(wlmat) ## [1] 0.8712195 phi(wlmat) ## [1] 0.4689508 2.5.3 De Vries Modified h value The most common measure of social hierarchy linearity is the modified h value by De Vries 1995. The devries function will provide the h value of a sociomatrix and associated p-value from a randomization test. devries(wlmat) ## $`h-modified` ## [1] 0.7586231 ## ## $`p-value` ## [1] 0 Its also possible to plot the results of the randomization test: devries(wlmat, plot=T) ## h-modified = 0.7587741 ## p-value= 0 2.5.4 Triangle Transitivity The third measure of hierarchical organization is the triangle transitivity suggested by Shizuka &amp; McDonald 2012. This measure calculate the proportion of transitive versus intransitive triads within the directed network. The index ranges between 0 and 1, with 1 indicating that all triads are transitive (i.e. there are no cycles). This function also provides output from a randomization test to assess if the proportion of transitive triads is higher than expected (i.e. there is hierarchical organization). ttri_test(wlmat) ## $Pt ## [1] 0.9527027 ## ## $ttri ## [1] 0.8108108 ## ## $pval ## [1] 0 This value can be ascertained quickly using ttri: ttri(wlmat) ## $Pt ## [1] 0.9527027 ## ## $ttri ## [1] 0.8108108 There are of course several other network measures that could be used to describe the hierarchical organiation of a social hierarchy, but I wont cover those here. 2.5.5 Steepness Another measure of hierarchies are how steep the individual differences in Davids Scores are - prosposed by De Vries et al 2006. The higher the steepness, the greater the differences between individual ranks in their ratings. The scores range between 0 and 1, with 1 having the greatest differences between ranks in scores. We can test this using the steepness package. library(steepness) steep &lt;- steepness::steeptest(wlmat, rep=10000) steep$Stp #Steepness ## [1] 0.5598867 sum( (steep$Stpsim &gt; steep$Stp) / 10000 ) #pvalue ## [1] 0 2.6 Individual Ranking Measures A proliferation of ranking methods exist to try and determine which individual is more dominant, powerful or influential in a group. Many of the more recent methods are network based (I will cover these in a future tutorial/primer), others come from the sports data literature. Here I will describe some standard methods used in animal behavior. 2.6.1 Davids Scores A simple measure is the Davids Scores of each individual. This can be considered to be the opponent-adjusted win proportion of each individual. Individuals with positive Davids Scores are more dominant. Individuals with negative Davids Scores are losing more fights. ds(wlmat) ## 1 10 11 12 2 3 4 ## -15.31674 -13.52634 11.59505 -18.63460 -21.89749 21.64528 55.85957 ## 5 6 7 8 9 ## -14.45596 15.03441 26.89502 -15.08334 -32.11487 Viewing this as a simple plot shows the steepness of Davids Scores: plot(1:12, rev(sort(ds(wlmat))), &quot;l&quot;, xlab = &quot;Rank&quot;, ylab = &quot;David&#39;s Score&quot;, main = &quot;David&#39;s Scores by Rank&quot;) abline(h = 0, col = &quot;red&quot;, lty = 3) 2.6.2 I&amp;SI Method A commonly used method is the linear ordering algorithm - the I&amp;SI ranking method. This attempts to shuffle the binary sociomatix such that 1s are all above the diagonal and 0s are all below the diagonal. Further, it tries to get 1s under the diagonal as close to it as possible. This is computationally expensive - and I need to implement this in C++ in the next version of the compete package. There are two versions of this algorithm - isi98 is the original method proposed here and isi13 is the updated method proposed here. I recommend using the former as the updated version is too slow for most matrices - and the additional benefit in improved linear ordering isnt huge. Also, it is worth running this procedure a few times to find the optimal ranking as it uses randomization to try and find the best matrix. The output gives the initial matrix order, the proposed best matrix, the I (number of inconsistencies), the SI (the strength of inconsistencies), and the best order of ranks. It also gives rs the correlation between the ranks proposed by the I&amp;SI method and the Davids Scores. Running this example several times, it appears as if the best solution is I=3, SI=10 and rs=0.88. isi.out &lt;- isi98(wlmat) ## ## INITIAL RANK: ## [1] &quot;4&quot; &quot;7&quot; &quot;3&quot; &quot;6&quot; &quot;11&quot; &quot;10&quot; &quot;5&quot; &quot;8&quot; &quot;1&quot; &quot;12&quot; &quot;2&quot; &quot;9&quot; ## I = 6 ## SI = 13 isi.out ## $best_matrix ## Recipient ## Actor 4 3 7 6 11 10 1 12 2 8 5 9 ## 4 0 79 76 53 64 28 21 22 40 43 16 38 ## 3 2 0 45 21 0 9 9 5 16 13 8 6 ## 7 0 1 0 33 11 32 5 9 16 17 4 22 ## 6 2 9 4 0 4 22 11 21 13 39 3 8 ## 11 0 8 2 3 0 5 13 5 3 2 1 9 ## 10 0 0 0 0 0 0 1 1 0 0 0 0 ## 1 1 1 0 3 0 0 0 1 3 2 2 6 ## 12 1 1 1 1 2 0 0 0 1 3 3 0 ## 2 0 1 2 0 2 0 0 0 0 2 0 1 ## 8 0 11 1 0 2 0 4 0 1 0 0 1 ## 5 1 0 0 3 0 0 2 0 0 0 0 1 ## 9 1 0 0 0 3 0 0 1 0 0 0 0 ## ## $best_order ## [1] &quot;4&quot; &quot;3&quot; &quot;7&quot; &quot;6&quot; &quot;11&quot; &quot;10&quot; &quot;1&quot; &quot;12&quot; &quot;2&quot; &quot;8&quot; &quot;5&quot; &quot;9&quot; ## ## $I ## [1] 3 ## ## $SI ## [1] 10 ## ## $rs ## [1] 0.8811189 2.6.3 Despotism Another metric we can calculate is the proportion of wins made by each animal. The proportion of wins made by the alpha male is that individuals despotism. Ill implement this as a function in the compete package in the future - at present, it can be found in the sourced code from GitHub above. despotism(wlmat) ## 4 7 6 3 11 8 1 12 2 5 9 10 ## 46.83 14.63 13.27 13.07 4.98 1.95 1.85 1.27 0.78 0.68 0.49 0.20 2.7 Plotting Sociomatrices We can also use the observed best ranking order of our choice to make a customized raw sociomatrix that we could use in a publication. This is using a ggplot2 based function I wrote called matrixplot. If you lookup the function, you can change the color scheme if you wish. matrixplot(wlmat, mylevs=isi.out$best_order) There is also a plot to color the binarized matrix based on the directional consistency of each relationship. The redder a cell, the higher the proportion of wins by that individual. This method is useful for quickly visualizing the inconsistencies in the hierarchy. matrixplot0(wlmat, mylevs=isi.out$best_order) Interestingly the relationship that has the most noticable inconsistency is id-11 vs id-3, where 11 beat 3 eight times but 3 never beat 11. This is despite 3 being higher ranked than 11. Often when examining all data over all days such inconsistencies may be the result of initial day 1 or day 2 interactions. This can be checked using the function contests. contests(df1,11,3) ## Timestamp Actor Behavior Recipient Location Observer Notes day ## 1: 2014-10-16 12:42:13 11 Subordinate 3 UR CW &lt;NA&gt; 3 ## 2: 2014-10-16 12:42:32 11 Chasing 3 UL CW &lt;NA&gt; 3 ## 3: 2014-10-16 13:25:25 11 Chasing 3 UL CW &lt;NA&gt; 3 ## 4: 2014-11-03 14:50:47 11 Chasing 3 UR AP &lt;NA&gt; 21 ## 5: 2014-11-03 14:51:49 11 Chasing 3 UR AP &lt;NA&gt; 21 ## 6: 2014-11-03 14:54:48 11 Chasing 3 UR AP &lt;NA&gt; 21 ## 7: 2014-11-03 14:57:49 11 Chasing 3 UR AP &lt;NA&gt; 21 ## 8: 2014-11-04 13:23:32 11 Induce-flee 3 UR WL &lt;NA&gt; 22 ## zhour score ## 1: 1 1 ## 2: 1 1 ## 3: 2 1 ## 4: 3 1 ## 5: 3 1 ## 6: 3 1 ## 7: 3 1 ## 8: 2 1 Here there are three early interactions on day 3, but 11 continues to beat 3 on the last two days of observation. This was by three separate observers suggesting that it is reliable. Most interestingly though, none of the agonistic interactions were fights - all were chases or induced subordinate behaviors (in our ethogram induced-flee means here that animal 11 caused 3 to flee and on row 1 that animal 11 caused animal 3 to show a subordinate posture. Clearly, there are many other methods for assessing the individual rankings/ratings of a social group. There are several network based metrics, matrix based measures, preferred comparison methods etc. I may cover these in a future primer. 2.8 Network Certainty Another valuable approach is to measure the certainty we have of each individuals ranking using network certainty. With this method, we can get the ranking of each individual according to their network position (akin to how much power or influence over others an individual has) and determine how certain we are of that ranking by examining the consistency of indirect relationships. We can use the Perc R package to do this. library(Perc) obsmat &lt;- as.conflictmat(wldf) DominanceProbability.obs &lt;- conductance(obsmat, maxLength = 2) s.rank.obs &lt;- simRankOrder(DominanceProbability.obs$p.hat, num = 10, kmax = 10) dfobs &lt;- merge(individualDomProb(DominanceProbability.obs$p.hat), s.rank.obs$BestSimulatedRankOrder) plot(dfobs$ranking, dfobs$Mean, xlab=&quot;Rank&quot;, ylab=&quot;Dominance Certainty&quot;) 2.9 Temporal Based Methods 2.9.1 Glicko Ratings There are a number of temporally based ratings methods that calculate dynamic changes in ratings over time. Two of these methods - ELO &amp; Glicko - are pairwise-contest models where all individuals start with an initial rating. Without any other knowledge about the individuals we assume they all have the same initial ratings. Individuals gain points for each win and lose points for each loss. The magnitude of the gain/loss in points is based on the ratings difference between contestants at a particular time. Each method has a constant value that adjusts this calculation. I prefer the Glicko method because it additionally has a standard deviation of ratings giving us a measure of how certain we are that individuals differ. The Glicko also has a decay function meaning that the rating uncertainty increases if individuals havent competed in a while. We could calculate ratings at the end of each day. Most primate studies use this approach. However, as we observe all animals all of the time, I prefer to recalculate ratings after every observation and use a smaller constant value (a higher constant value makes the ratins more volatile - they respond to changes more rapidly). We can use the PlayerRatings package to calculate the Glicko ratings like this: library(PlayerRatings) df1 &lt;- df1[order(df1$Timestamp),] #ensure in date order df1$event &lt;- 1:nrow(df1) glick.df &lt;- df1[, c(11,2,4,10), with = FALSE] #need event, actor, recipient, score gl &lt;- glicko(glick.df, history=T, cval=2) gl ## ## Glicko Ratings For 12 Players Playing 1031 Games ## ## Player Rating Deviation Games Win Draw Loss Lag ## 1 4 2866 58.04 489 480 1 8 0 ## 2 3 2367 49.09 247 134 2 111 15 ## 3 7 2319 44.76 281 150 0 131 45 ## 4 6 2254 41.33 255 136 2 117 1 ## 5 11 2242 56.02 140 51 1 88 7 ## 6 1 2030 64.35 86 19 1 66 16 ## 7 5 2017 83.67 44 7 0 37 34 ## 8 8 1928 55.20 141 20 0 121 24 ## 9 12 1927 68.72 78 13 0 65 1 ## 10 2 1849 69.54 104 8 3 93 7 ## 11 9 1771 73.70 98 5 1 92 14 ## 12 10 1714 85.92 99 2 1 96 0 Of course, the choice of cval affects how volatile individual ratings are. When recalculating ratings after every behavioral interaction, we have found that a lower value of cval provides stable rankings that most strongly reflect the rankings of animals as determined by other methods. How Glicko ratings change over time can be calculated using the basic plot function: plot(gl,npl=12) The above base r plot is not aesthetically pleasing. I have created a default function that allows us to take a glicko object and convert this to a more attractive plot. plotglicko(glick.df, cval=2, ylim1=1500, ylim2=3000, thetitle=&quot;Glicko Ratings over Time&quot;,linewd=.5) We can also plot the final glicko ratings by rank and show the deviations in ratings scores. ggplot(gl$ratings, aes(x=1:12, y=Rating)) + geom_point(size=2) + scale_x_continuous(breaks=1:12, labels=gl$ratings$Player)+ geom_errorbar(aes(ymin=Rating-Deviation, ymax=Rating+Deviation), width=.2, position=position_dodge(.9), size=.5) + geom_hline(yintercept=2200, color=&#39;red&#39;, linetype=&#39;dotted&#39;)+ ylab(&quot;Glicko Rating (Mean ± SD)&quot;) + xlab(&quot;Animal ID&quot;) + theme_classic() + ggtitle(&quot;Final Glicko Ratings&quot;) 2.9.2 Stability Indices To examine how stable rankings are across time, one could use the stability index suggested by Neumann et al 2011 and improved upon by Mcdonald &amp; Shizuka 2013. This essentially assesses how many ranking changes there have been across days between two time-points. It ranges between 0 and 1 with 1 indicating complete stability and 0 indicating complete instability in ranking. Here, I will evaluate stability across the whole period using the ELO method as the baseline for assessing ranks. There could be many modifications to this - we could use a different method for determining ratings on each day, we could use a different time-point for comparison (e.g. per hour), we could also change the constant in the ELO formula. There is also a weighting factor in this algorithm that accounts for whether to penalize rank changes among higher ranked animals as more impactful on stability. In the example below, Ive used the default weighting factor, though the function of this weighting could be adjusted. I may write more about this in the future. We will use the EloRating package to calculate this. df1.st &lt;- df1[score==1] # we only consider wins at the moment df1.st$Date &lt;- as.character(as.Date(df1.st$Timestamp)) #ELO stability function requires a character vector of form &quot;YYYY-MM-DD&quot; SEQ &lt;- EloRating::elo.seq(winner=df1.st$Actor, loser=df1.st$Recipient, Date=df1.st$Date, k=100, progressbar=FALSE) #note that could change k-factor here; k=100 default SI &lt;- EloRating::stab_elo(SEQ, from=min(SEQ$stability$date),to=max(SEQ$stability$date), weight=T) SI ## [1] 0.9138 Again, there are many other dynamic network based measures of individual ratings that we could use instead. Depending on the data collected and the question of interest, there may be benefits to choosing these methods. I may write a primer on these also in the future. 2.9.3 Temporal Social Dynamics Calculating indices of hierarchical organization using all data at once may not be suitable. We may, for instance, wish to see how one metric changes over time. Here, we will look at how triangle transitivity changes over time. Below, we split the raw data into a new dataframe for everyday containing data from day 1 up to that day. Therefore there are 21 dataframes in total (as there are 21 days worth of data - although the last day of observations was 22, we did not have any observations for day 20). wlmat.days &lt;- lapply( Reduce(rbind, split(df1, df1$day), accumulate=TRUE), function(x) get_wl_matrix(x[score==1][, c(2,4), with = FALSE]) ) wlmat.days[[1]] ## Recipient ## Actor 1 10 11 2 3 4 5 6 7 8 9 ## 1 0 0 0 0 0 0 0 0 0 1 0 ## 10 0 0 0 0 0 0 0 0 0 0 0 ## 11 0 0 0 0 0 0 0 0 0 0 0 ## 2 0 0 0 0 0 0 0 0 0 0 0 ## 3 0 0 0 0 0 1 0 1 0 0 0 ## 4 4 1 2 4 1 0 2 0 1 1 0 ## 5 2 0 0 0 0 0 0 0 0 0 0 ## 6 1 2 0 1 0 0 1 0 0 0 0 ## 7 0 0 0 0 0 0 0 0 0 0 0 ## 8 0 0 0 0 0 0 0 0 0 0 0 ## 9 0 0 1 0 0 0 0 0 0 0 0 The above matrix is the winner-loser sociomatrix based on only day 1 data. We can then plot how triangle transitivity changes across days: plot(c(1:19,21:22), unlist(lapply(wlmat.days, function(x) ttri(x)$ttri)), &quot;l&quot;, xlab = &quot;Day&quot;, ylab = &quot;Triangle Transitivity&quot;, main = &quot;Change in Triangle Transitivity over Days&quot;) Of course, we could prefer to use a different temporal strategy. For instance, we could use a sliding window approach looking at how triangle transitivity changes for e.g. 3 days at a time. So we would plot ttri for days 1-3, then days 2-4, 3-5 etc. Another extension of this approach is something we discussed in our Animal Behaviour paper. At the end of each day, we could only keep the last n interactions between any pair of individuals. This has the advantage of not including behavioral events that occurred long before the day of interest. For example, if animal A had accrued 100 wins against B and B had never beaten A, then if that relationships changed on e.g. day 10 it could take several days to register in the ttri - because it could take a long time for B to get more than 100 wins against A to flip that relationship. Only considering e.g. the last 3 interactions overcomes this issue. To do these calculations we can use a function I wrote that we have already sourced from GitHub above. ttri_N &lt;- lapply( Reduce(rbind, split(df1, df1$day), accumulate=TRUE), function(x) ttri_lastN(x, N=3) ) plot(c(1:19,21:22), unlist(ttri_N), &quot;l&quot;, xlab = &quot;Day&quot;, ylab = &quot;Triangle Transitivity&quot;, main = &quot;Change in Triangle Transitivity \\n using 3 most recent interactions&quot;) 2.10 Summary In this brief primer, I have shown you how to import the raw data, clean the data up for analysis, calculate measures of overall hierarchical nature of the group and calculate individual metrics of dominance. Ive also shown how to look at some temporal dynamics. "],["plotting-sociomatrices-1.html", "Chapter 3 Plotting Sociomatrices 3.1 Raw Sociomatrices 3.2 Dichotomized Sociomatrices 3.3 Multiple Sociomatrices", " Chapter 3 Plotting Sociomatrices This chapter describes in detail how we make our sociomatrices using the ggplot2 package. We assume that you already have data in a sociomatrix. We will start with one such matrix - the mouse matrix that is available in the compete package. # devtools::install_github(&#39;jalapic/compete&#39;) library(compete) mouse ## A B C D E F G H I J K L ## A 0 0 0 1 0 0 2 0 0 0 0 0 ## B 1 0 1 1 0 0 0 0 1 0 0 0 ## C 0 2 0 1 0 1 1 0 1 0 0 1 ## D 0 0 1 0 0 1 1 0 0 0 0 1 ## E 0 1 0 0 0 0 0 0 0 0 0 0 ## F 0 0 2 2 0 0 2 0 0 0 3 1 ## G 1 2 1 1 0 0 0 0 0 1 0 2 ## H 4 7 4 4 5 6 2 0 5 7 14 5 ## I 0 2 0 1 1 0 1 0 0 0 3 0 ## J 5 8 6 2 7 15 3 4 1 0 25 6 ## K 1 5 6 1 2 9 5 2 4 1 0 2 ## L 0 1 0 0 0 2 0 2 0 0 1 0 These data are actually stored in a data.frame of 12 rows and 12 columns: str(mouse) ## &#39;data.frame&#39;: 12 obs. of 12 variables: ## $ A: int 0 1 0 0 0 0 1 4 0 5 ... ## $ B: int 0 0 2 0 1 0 2 7 2 8 ... ## $ C: int 0 1 0 1 0 2 1 4 0 6 ... ## $ D: int 1 1 1 0 0 2 1 4 1 2 ... ## $ E: int 0 0 0 0 0 0 0 5 1 7 ... ## $ F: int 0 0 1 1 0 0 0 6 0 15 ... ## $ G: int 2 0 1 1 0 2 0 2 1 3 ... ## $ H: int 0 0 0 0 0 0 0 0 0 4 ... ## $ I: int 0 1 1 0 0 0 0 5 0 1 ... ## $ J: int 0 0 0 0 0 0 1 7 0 0 ... ## $ K: int 0 0 0 0 0 3 0 14 3 25 ... ## $ L: int 0 0 1 1 0 1 2 5 0 6 ... 3.1 Raw Sociomatrices The first step we need to do is to convert the sociomatrix dataframe into long format data so we can give x and y coordinates. We can do this using the melt function from the reshape2 package. We ensure that this output is a data.frame using data.frame(). In case our diagonal had NA entries, we also only keep complete cases. #make the df we will use for plotting m.dat &lt;- reshape2::melt(mouse) m.dat &lt;- data.frame(m.dat) m.dat &lt;- m.dat[complete.cases(m.dat),] #removing NAs head(m.dat) ## variable value ## 1 A 0 ## 2 A 1 ## 3 A 0 ## 4 A 0 ## 5 A 0 ## 6 A 0 tail(m.dat) ## variable value ## 139 L 2 ## 140 L 5 ## 141 L 0 ## 142 L 6 ## 143 L 2 ## 144 L 0 This just gives 2 columns of output. A variable column which refers to the original column that the value entry came from. We need to add a new column that gives the row location. These are in the order A-&gt;L. We could just add that column like this: m.dat$row.id &lt;- LETTERS[1:12] head(m.dat) ## variable value row.id ## 1 A 0 A ## 2 A 1 B ## 3 A 0 C ## 4 A 0 D ## 5 A 0 E ## 6 A 0 F tail(m.dat) ## variable value row.id ## 139 L 2 G ## 140 L 5 H ## 141 L 0 I ## 142 L 6 J ## 143 L 2 K ## 144 L 0 L At this point, there are two main things that we should do before plotting. i) Decide whether to remove zeros - as sociomatrices generally look better without them in. ii) Reorder the ids by their dominance. Lets first make a very basic plot without doing either of these things. We use geom_tile() from ggplot2 to make our plot, and use geom_text() to add in the value. The x axis should be the loser (column from original sociomatrix) and the y axis should be the winner (row from the original sociomatrix). The parameters inside geom_tile() define the color, fill and size of each tile. The parameter label= inside geom_text() define which column supplies the text. We also dictate the color and size of the text. library(tidyverse) p &lt;- ggplot(m.dat, aes(x=variable, y=row.id)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;, fill=&#39;white&#39;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() p There are a number of other things that are wrong with this plot. First, it is more readable to have the labels on the x-axis at the top of the plot. We can do this as follows, while also labeling the axes with new titles: p &lt;- p + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) p It still isnt quite right. We can adjust a number of other theme elements to make the plot look better: p &lt;- p + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) p This looks better, but it still has three issues. The ids are in alphabetical order as opposed to being in dominance order. The matrix is full of zeros which make it harder to read. Finally, all tiles are filled with white, when it would be more readable to fill with a color that depicts the value of the cell/tile. Lets first remove the zeros. This should be done when we create the data.frame after melting. We substitute zeros with NAs. m.dat[m.dat == 0] &lt;- NA head(m.dat) ## variable value row.id ## 1 A NA A ## 2 A 1 B ## 3 A NA C ## 4 A NA D ## 5 A NA E ## 6 A NA F tail(m.dat) ## variable value row.id ## 139 L 2 G ## 140 L 5 H ## 141 L NA I ## 142 L 6 J ## 143 L 2 K ## 144 L NA L We can now replot using the same plotting code as above: p &lt;- ggplot(m.dat, aes(x=variable, y=row.id)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;, fill=&#39;white&#39;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) p Reordering the order of individuals on the rows and columns requires a bit more thought. The best way to reorder would be based on some measure of dominance. For this example, we are going to choose to reorder the ids based on Davids Scores. We could pick other ranking methods though such as I&amp;SI. To reorder by Davids Scores, we first must calculate the Davids Scores of each individual. We will use the ds function from the compete package: v &lt;- ds(mouse) v ## A B C D E F ## -7.50702839 -20.20524267 -8.08154762 -16.11250000 -7.58202839 -4.25514347 ## G H I J K L ## -9.33750000 36.78053221 -0.06417125 34.27341270 13.91740735 -11.82619048 We can reorder this vector and grab the names in descending order: v1 &lt;- rev(names(v)[order(v)]) v1 ## [1] &quot;H&quot; &quot;J&quot; &quot;K&quot; &quot;I&quot; &quot;F&quot; &quot;A&quot; &quot;E&quot; &quot;C&quot; &quot;G&quot; &quot;L&quot; &quot;D&quot; &quot;B&quot; Now we have the order of individuals by their dominance. We can factorize our two columns containing the individual ids and set their levels. We actually have to make the levels of the winners the reverse order. m.dat$variable &lt;- factor(m.dat$variable, levels=v1) m.dat$row.id &lt;- factor(m.dat$row.id, levels = rev(v1)) str(m.dat) ## &#39;data.frame&#39;: 144 obs. of 3 variables: ## $ variable: Factor w/ 12 levels &quot;H&quot;,&quot;J&quot;,&quot;K&quot;,&quot;I&quot;,..: 6 6 6 6 6 6 6 6 6 6 ... ## $ value : int NA 1 NA NA NA NA 1 4 NA 5 ... ## $ row.id : Factor w/ 12 levels &quot;B&quot;,&quot;D&quot;,&quot;L&quot;,&quot;G&quot;,..: 7 1 5 2 6 8 4 12 9 11 ... We can now replot the sociomatrix with the order of the ids now set: p &lt;- ggplot(m.dat, aes(x=variable, y=row.id)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;, fill=&#39;white&#39;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) p Davids Scores are a quick way of determining rank, but lets instead go with the more formal I&amp;SI rankings. We can calculate these using the isi98 function in the compete package: isi &lt;- isi98(mouse) ## ## INITIAL RANK: ## [1] &quot;H&quot; &quot;J&quot; &quot;K&quot; &quot;I&quot; &quot;F&quot; &quot;A&quot; &quot;E&quot; &quot;C&quot; &quot;G&quot; &quot;L&quot; &quot;D&quot; &quot;B&quot; ## I = 5 ## SI = 17 isi ## $best_matrix ## H J K F C I E A G L B D ## H 0 7 14 6 4 5 5 4 2 5 7 4 ## J 4 0 25 15 6 1 7 5 3 6 8 2 ## K 2 1 0 9 6 4 2 1 5 2 5 1 ## F 0 0 3 0 2 0 0 0 2 1 0 2 ## C 0 0 0 1 0 1 0 0 1 1 2 1 ## I 0 0 3 0 0 0 1 0 1 0 2 1 ## E 0 0 0 0 0 0 0 0 0 0 1 0 ## A 0 0 0 0 0 0 0 0 2 0 0 1 ## G 0 1 0 0 1 0 0 1 0 2 2 1 ## L 2 0 1 2 0 0 0 0 0 0 1 0 ## B 0 0 0 0 1 1 0 1 0 0 0 1 ## D 0 0 0 1 1 0 0 0 1 1 0 0 ## ## $best_order ## [1] &quot;H&quot; &quot;J&quot; &quot;K&quot; &quot;F&quot; &quot;C&quot; &quot;I&quot; &quot;E&quot; &quot;A&quot; &quot;G&quot; &quot;L&quot; &quot;B&quot; &quot;D&quot; ## ## $I ## [1] 3 ## ## $SI ## [1] 11 ## ## $rs ## [1] 0.9300699 We can graph the dominance rankings directly from the $best_order output. Its noticeable that this order differs quite a bit from the Davids Scores rankings: isi$best_order ## [1] &quot;H&quot; &quot;J&quot; &quot;K&quot; &quot;F&quot; &quot;C&quot; &quot;I&quot; &quot;E&quot; &quot;A&quot; &quot;G&quot; &quot;L&quot; &quot;B&quot; &quot;D&quot; v1 ## [1] &quot;H&quot; &quot;J&quot; &quot;K&quot; &quot;I&quot; &quot;F&quot; &quot;A&quot; &quot;E&quot; &quot;C&quot; &quot;G&quot; &quot;L&quot; &quot;D&quot; &quot;B&quot; We will then refactor our two columns based on these rankings. m.dat$variable &lt;- factor(m.dat$variable, levels=isi$best_order) m.dat$row.id &lt;- factor(m.dat$row.id, levels = rev(isi$best_order)) str(m.dat) ## &#39;data.frame&#39;: 144 obs. of 3 variables: ## $ variable: Factor w/ 12 levels &quot;H&quot;,&quot;J&quot;,&quot;K&quot;,&quot;F&quot;,..: 8 8 8 8 8 8 8 8 8 8 ... ## $ value : int NA 1 NA NA NA NA 1 4 NA 5 ... ## $ row.id : Factor w/ 12 levels &quot;D&quot;,&quot;B&quot;,&quot;L&quot;,&quot;G&quot;,..: 5 2 8 1 6 9 4 12 7 11 ... And we can replot the matrix based on this order p &lt;- ggplot(m.dat, aes(x=variable, y=row.id)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;, fill=&#39;white&#39;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) p This now is starting to look like a proper sociomatrix. There are however quite a few numbers under the diagonal. Its not immediately obvious which numbers are inconsistencies - i.e. when the individual in the row is a winner over the individual in the column. For instance, L beats F 2 times, whereas F beats L 1 time only. Therefore this is an inconsistent relationship. However, L beats H 2 times, but H beats L 5 times, so this is not inconsistent. One way we could fill these tiles would just be based on the value of the cell. This can be done using scale_fill_gradient(). To this we need to supply a fill color for the lowest value (which is actually 1 not 0 as we removed them) and a fill color for the highest value. We also need to add fill=value inside the ggplot() function - we also remove fill=\"white\" from the geom_tile() function. p &lt;- ggplot(m.dat, aes(x=variable, y=row.id, fill=value)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) + scale_fill_gradient( low = &quot;white&quot;, high = &quot;red1&quot;, space = &quot;Lab&quot;, na.value = &quot;white&quot;, guide = &quot;colourbar&quot;) p This looks ok, but the shading is heavily skewed by the highest value. One alternatively strategy would be to log the value column, and supply that information as the new fill value. To do this, we would add a new column to the data.frame. m.dat$value_log &lt;- log(m.dat$value) p &lt;- ggplot(m.dat, aes(x=variable, y=row.id, fill=value_log)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) + scale_fill_gradient( low = &quot;white&quot;, high = &quot;red1&quot;, space = &quot;Lab&quot;, na.value = &quot;white&quot;, guide = &quot;colourbar&quot;) p This looks a bit better. Another way to represent the relationships is by filling the tile with a shade of color that represents the directional consistency of each relationship. We can do that by adding a new column to the data.frame which represents the directional consistency of each measure. We can calculate this directly from the original matrix. dcs &lt;- mouse / (mouse + t(mouse)) m.dat$DC &lt;- reshape2::melt(dcs)[,2] head(m.dat) ## variable value row.id value_log DC ## 1 A NA A NA NaN ## 2 A 1 B 0 1 ## 3 A NA C NA NaN ## 4 A NA D NA 0 ## 5 A NA E NA NaN ## 6 A NA F NA NaN tail(m.dat) ## variable value row.id value_log DC ## 139 L 2 G 0.6931472 1.0000000 ## 140 L 5 H 1.6094379 0.7142857 ## 141 L NA I NA NaN ## 142 L 6 J 1.7917595 1.0000000 ## 143 L 2 K 0.6931472 0.6666667 ## 144 L NA L NA NaN Now we can plot based on this measure: p &lt;- ggplot(m.dat, aes(x=variable, y=row.id, fill=DC)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) + scale_fill_gradient( low = &quot;white&quot;, high = &quot;red1&quot;, space = &quot;Lab&quot;, na.value = &quot;white&quot;, guide = &quot;colourbar&quot;) p Except this looks confusing. It would be better only to color the tiles when the animal is dominant and exclude those who are not. We can check for each pair of individuals which has the highest directional consistency by checking the matrix of directional consistencies against its transpose. We then assign a NA to any cell that is not greater than its transpose: dcs[dcs&lt;=t(dcs)]&lt;-NA dcs ## A B C D E F G H I ## A NaN NA NaN 1.0000000 NaN NaN 0.6666667 NA NaN ## B 1 NaN NA 1.0000000 NA NaN NA NA NA ## C NaN 0.6666667 NaN NA NaN NA NA NA 1.0000000 ## D NA NA NA NaN NaN NA NA NA NA ## E NaN 1.0000000 NaN NaN NaN NaN NaN NA NA ## F NaN NaN 0.6666667 0.6666667 NaN NaN 1.0000000 NA NaN ## G NA 1.0000000 NA NA NaN NA NaN NA NA ## H 1 1.0000000 1.0000000 1.0000000 1 1.0000000 1.0000000 NaN 1.0000000 ## I NaN 0.6666667 NA 1.0000000 1 NaN 1.0000000 NA NaN ## J 1 1.0000000 1.0000000 1.0000000 1 1.0000000 0.7500000 NA 1.0000000 ## K 1 1.0000000 1.0000000 1.0000000 1 0.7500000 1.0000000 NA 0.5714286 ## L NaN 1.0000000 NA NA NaN 0.6666667 NA NA NaN ## J K L ## A NA NA NaN ## B NA NA NA ## C NA NA 1.0000000 ## D NA NA 1.0000000 ## E NA NA NaN ## F NA NA NA ## G NA NA 1.0000000 ## H 0.6363636 0.8750000 0.7142857 ## I NA NA NaN ## J NaN 0.9615385 1.0000000 ## K NA NaN 0.6666667 ## L NA NA NaN We now can melt this matrix to provide the new fill values of directional consistency and use those for plotting: m.dat$DC1 &lt;- reshape2::melt(dcs)[,2] # only need 2nd column of melt output p &lt;- ggplot(m.dat, aes(x=variable, y=row.id, fill=DC1)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) + scale_fill_gradient( low = &quot;white&quot;, high = &quot;red1&quot;, space = &quot;Lab&quot;, na.value = &quot;white&quot;, guide = &quot;colourbar&quot;) p But wait, there is actually however one mistake with this plot. Remeber that scale_fill_manual() fills the colors of the plot from lowest to highest, making the lowest equal to white. As we plotted the above plot based on DC1column which was only keeping the highest directional consistency value for each relationship, that means one of these high DC values is still the lowest in that column. We can find it: min(m.dat$DC1,na.rm=T) ## [1] 0.5714286 which(m.dat$DC1 == min(m.dat$DC1,na.rm=T)) ## [1] 107 m.dat[107,] # I vs K ## variable value row.id value_log DC DC1 ## 107 I 4 K 1.386294 0.5714286 0.5714286 It turns out that K beat I 4 times, and I beat K 3 times - giving K a directional consistency of 0.57 over I. When looking at the above plot, you will notice that the tile in the row of K and column of I which has a 4 in it is white. Technically, this should be a very pale red color. How do we fix this ? Essentially we need to put some DC values back into this column. But we need to choose wisely. Should we pick a value of 0? This then might skew the range of colors, although DC does vary between 0 and 1. Alternatively, we could pick 0.5 as we are only interested in looking at the higher DC values. In this example, Ill pick 0.5 as the cutoff value. What we should do is replace and NA values in the DC1 column with 0.5 m.dat$DC1 &lt;- ifelse(is.na(m.dat$DC1), 0.5, m.dat$DC1) tail(m.dat) ## variable value row.id value_log DC DC1 ## 139 L 2 G 0.6931472 1.0000000 1.0000000 ## 140 L 5 H 1.6094379 0.7142857 0.7142857 ## 141 L NA I NA NaN 0.5000000 ## 142 L 6 J 1.7917595 1.0000000 1.0000000 ## 143 L 2 K 0.6931472 0.6666667 0.6666667 ## 144 L NA L NA NaN 0.5000000 Now, lets replot: p &lt;- ggplot(m.dat, aes(x=variable, y=row.id, fill=DC1)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) + scale_fill_gradient( low = &quot;white&quot;, high = &quot;red1&quot;, space = &quot;Lab&quot;, na.value = &quot;white&quot;, guide = &quot;colourbar&quot;) p Notice that now the tile K-I with a 4 in it is now filled with color, but all the others that should be white are still white. 3.2 Dichotomized Sociomatrices We can plot dichotomized sociomatrices in two ways. The first would be to use the function get_di_matrix() from the compete package to generate a dichotomized matrix. We would then go through similar steps as above. This is the dichotomized matrix: get_di_matrix(mouse) ## A B C D E F G H I J K L ## A 0 0 0 1 0 0 1 0 0 0 0 0 ## B 1 0 0 1 0 0 0 0 0 0 0 0 ## C 0 1 0 0 0 0 0 0 1 0 0 1 ## D 0 0 0 0 0 0 0 0 0 0 0 1 ## E 0 1 0 0 0 0 0 0 0 0 0 0 ## F 0 0 1 1 0 0 1 0 0 0 0 0 ## G 0 1 0 0 0 0 0 0 0 0 0 1 ## H 1 1 1 1 1 1 1 0 1 1 1 1 ## I 0 1 0 1 1 0 1 0 0 0 0 0 ## J 1 1 1 1 1 1 1 0 1 0 1 1 ## K 1 1 1 1 1 1 1 0 1 0 0 1 ## L 0 1 0 0 0 1 0 0 0 0 0 0 Alternatively, if we have already gone through the above steps, we can simply piggy-back on the plot we just made based on the directional consistency. In this plot, the only tiles that receive a color are those with a directional consistency above 0.5, which is exactly what we want for a dichotomized matrix. All we need to do is replace the text values. We no longer want the raw values, but a 1 if their directional consistency is above 0.5. All we need to do is create a new value column and populate with 1s when the DC &gt; 0.5 using an ifelse() statement: m.dat$value1 &lt;- ifelse(m.dat$DC1&gt;.5, 1, NA) We can then replot putting in this new text: p &lt;- ggplot(m.dat, aes(x=variable, y=row.id, fill=DC1)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;) + geom_text(aes(label = value1), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) + scale_fill_gradient( low = &quot;white&quot;, high = &quot;red1&quot;, space = &quot;Lab&quot;, na.value = &quot;white&quot;, guide = &quot;colourbar&quot;) p 3.3 Multiple Sociomatrices If we want to plot multiple sociomatrices we need to consider how to color the tiles. As an example here are some data that have three groups of four mice: df &lt;- read_csv(&quot;https://gist.githubusercontent.com/jalapic/98d09d5c98e28276e81d3bc3de3e3832/raw/2175e26485d5b9790c7ef48bf14f94a96e16a4b9/threegroups.csv&quot;) head(df) ## # A tibble: 6 x 4 ## Group id1 id2 value ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 A A 0 ## 2 1 A B 15 ## 3 1 A C 11 ## 4 1 A D 8 ## 5 1 B A 3 ## 6 1 B B 0 tail(df) ## # A tibble: 6 x 4 ## Group id1 id2 value ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 3 C C 0 ## 2 3 C D 7 ## 3 3 D A 2 ## 4 3 D B 4 ## 5 3 D C 4 ## 6 3 D D 0 We can look at the win-loss matrices from each of these three groups: mats &lt;- split(df, df$Group) %&gt;% map(~ reshape2::acast(., id1~id2, value.var=&quot;value&quot;)) mats ## $`1` ## A B C D ## A 0 15 11 8 ## B 3 0 4 2 ## C 0 0 0 1 ## D 0 0 0 0 ## ## $`2` ## A B C D ## A 0 0 0 1 ## B 2 0 1 1 ## C 4 6 0 3 ## D 4 5 2 0 ## ## $`3` ## A B C D ## A 0 3 0 5 ## B 33 0 24 7 ## C 11 3 0 7 ## D 2 4 4 0 One approach would be to create three separate matrices and plot them side by side. Lets first create a plotting function that will color the tiles by the number of wins in each matrix. Then well apply that function to each of the three groups separately. Here is the function: make_plot &lt;- function(mat){ # Although plotting by value, adding in code that would enable filling by DC # melt matrix back to df m.dat &lt;- reshape2::melt(mat) m.dat &lt;- data.frame(m.dat) m.dat &lt;- m.dat[complete.cases(m.dat),] #removing NAs # remove 0s from value column m.dat$value &lt;- ifelse(m.dat$value==0, NA, m.dat$value) # factorize ids by rank order isi &lt;- isi98(mat) m.dat$Var2 &lt;- factor(m.dat$Var2, levels=isi$best_order) m.dat$Var1 &lt;- factor(m.dat$Var1, levels = rev(isi$best_order)) # create directional consistency column dcs &lt;- mat / (mat + t(mat)) m.dat$DC &lt;- reshape2::melt(dcs)[,3] # create directional consistency column only &gt;0.5 dcs[dcs&lt;=t(dcs)]&lt;-NA m.dat$DC1 &lt;- reshape2::melt(dcs)[,3] # put in .5 as minimum DC column m.dat$DC1 &lt;- ifelse(is.na(m.dat$DC1), .5, m.dat$DC1) # put in 0 as minimum in value1 column for fill m.dat$value1 &lt;- ifelse(is.na(m.dat$value), .5, m.dat$value) # plot p &lt;- ggplot(m.dat, aes(x=Var2, y=Var1, fill=value1)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;) + geom_text(aes(label = value), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) + scale_fill_gradient( low = &quot;white&quot;, high = &quot;red1&quot;, space = &quot;Lab&quot;, na.value = &quot;white&quot;, guide = &quot;colourbar&quot;) return(p) } Now we will create individual plots and put them together using gridExtra. p1 &lt;- make_plot(mats[[1]]) p2 &lt;- make_plot(mats[[2]]) p3 &lt;- make_plot(mats[[3]]) library(gridExtra) grid.arrange(p1,p2,p3, nrow=1) Hopefully you notice what the problem is with this approach. The highest value in each matrix(15, 6, 33) is the same shade of red which is misleading. What we have to do instead is scale the fill color based on the whole range of values across all matrices. The best way to do this is to have all of the data in one dataframe and create a scale based on the value column. We can do that as follows: df$scale_value &lt;- (df$value-min(df$value)) / ((max(df$value)-min(df$value))) head(df) ## # A tibble: 6 x 5 ## Group id1 id2 value scale_value ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 A A 0 0 ## 2 1 A B 15 0.455 ## 3 1 A C 11 0.333 ## 4 1 A D 8 0.242 ## 5 1 B A 3 0.0909 ## 6 1 B B 0 0 We next have to piece that scale_value back. The best way to do this is to start right back from the original data.frame including all groups. But before we do that, lets create all the data.frames we need for plotting and store them in a list: # Get matrices mats &lt;- split(df, df$Group) %&gt;% map(~ reshape2::acast(., id1~id2, value.var=&quot;value&quot;)) # make dataframe for plotting dx &lt;- mats %&gt;% map(~ reshape2::melt(.)) %&gt;% map(~ data.frame(.)) %&gt;% map(~ mutate(., value0 = ifelse(value==0, NA, value))) # get rank orders l &lt;- lapply(mats, isi98) %&gt;% map(~ .$best_order) We can look at these like this: lapply(dx, head) ## $`1` ## Var1 Var2 value value0 ## 1 A A 0 NA ## 2 B A 3 3 ## 3 C A 0 NA ## 4 D A 0 NA ## 5 A B 15 15 ## 6 B B 0 NA ## ## $`2` ## Var1 Var2 value value0 ## 1 A A 0 NA ## 2 B A 2 2 ## 3 C A 4 4 ## 4 D A 4 4 ## 5 A B 0 NA ## 6 B B 0 NA ## ## $`3` ## Var1 Var2 value value0 ## 1 A A 0 NA ## 2 B A 33 33 ## 3 C A 11 11 ## 4 D A 2 2 ## 5 A B 3 3 ## 6 B B 0 NA Next we need to add the scale column. Again, we can do this to each element of the list using a loop: df.l &lt;- split(df, df$Group) out &lt;- NULL for(i in 1:length(l)){ df.l[[i]]$Var1 &lt;- df.l[[i]]$id1 df.l[[i]]$Var2 &lt;- df.l[[i]]$id2 out[[i]] &lt;- full_join(dx[[i]],df.l[[i]]) # factorize out[[i]]$Var2 &lt;- factor(out[[i]]$Var2, levels=l[[i]]) out[[i]]$Var1 &lt;- factor(out[[i]]$Var1, levels = rev(l[[i]])) } lapply(out,head) ## [[1]] ## Var1 Var2 value value0 Group id1 id2 scale_value ## 1 A A 0 NA 1 A A 0.00000000 ## 2 B A 3 3 1 B A 0.09090909 ## 3 C A 0 NA 1 C A 0.00000000 ## 4 D A 0 NA 1 D A 0.00000000 ## 5 A B 15 15 1 A B 0.45454545 ## 6 B B 0 NA 1 B B 0.00000000 ## ## [[2]] ## Var1 Var2 value value0 Group id1 id2 scale_value ## 1 A A 0 NA 2 A A 0.00000000 ## 2 B A 2 2 2 B A 0.06060606 ## 3 C A 4 4 2 C A 0.12121212 ## 4 D A 4 4 2 D A 0.12121212 ## 5 A B 0 NA 2 A B 0.00000000 ## 6 B B 0 NA 2 B B 0.00000000 ## ## [[3]] ## Var1 Var2 value value0 Group id1 id2 scale_value ## 1 A A 0 NA 3 A A 0.00000000 ## 2 B A 33 33 3 B A 1.00000000 ## 3 C A 11 11 3 C A 0.33333333 ## 4 D A 2 2 3 D A 0.06060606 ## 5 A B 3 3 3 A B 0.09090909 ## 6 B B 0 NA 3 B B 0.00000000 We can very nearly do the plotting. However, there is still one thing to fix. Previously, the scale_fill_manual() worked by setting a range between two colors based on the values in a particular column. This time, we want the fill to be based on the scale_value column which ranges from 0 to 1 across the data but may range between any values in between for any given data.frame. Therefore, we need to scale the fill slightly differently. make_scale_plot &lt;- function(df){ p &lt;- ggplot(df, aes(x=Var2, y=Var1, fill=scale_value)) + geom_tile(color=&quot;black&quot;, size=0.5, stat=&quot;identity&quot;) + geom_text(aes(label = value0), color=&quot;black&quot;, size=rel(3.5)) + theme_classic() + scale_x_discrete(expand = c(0, 0), position = &quot;top&quot;) + scale_y_discrete(expand = c(0, 0)) + xlab(&quot;Loser&quot;) + ylab(&quot;Winner&quot;) + theme(axis.text.x = element_text(vjust = 1), axis.text.y = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(fill=NA,color=&quot;black&quot;, size=0.5, linetype=&quot;solid&quot;), axis.line = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill=&quot;white&quot;), plot.background = element_rect(fill=&quot;white&quot;), axis.text = element_text(color=&quot;#3C3C3C&quot;, size=rel(1.1)), legend.position = &quot;none&quot; ) + scale_fill_gradientn( limits = c(0,1), colors=c(&quot;white&quot;, &quot;red1&quot;) ) return(p) } We can finally plot each matrix side-by-side: pp1 &lt;- make_scale_plot(out[[1]]) pp2 &lt;- make_scale_plot(out[[2]]) pp3 &lt;- make_scale_plot(out[[3]]) grid.arrange(pp1,pp2,pp3, nrow=1) There are clearly many improvements that could be made. The code could definitely be cleaned up for the multiple sociomatrices. We also probably dont want to have Winner and Loser labels on every matrix. There are probably other things we could do better too. "],["social-networks.html", "Chapter 4 Social Networks 4.1 Permutation Methods", " Chapter 4 Social Networks This section will contain some examples of topics we need to consider in social network analysis. This chapter is intended for students working in my lab who are interested in social network analysis. It is a work in progress (i.e. Ive barely scratched the surface). I have some materials for social network analysis available on GitHub. Also see this primer for more information on how to use igraph. 4.1 Permutation Methods There has been a lot of recent discussion about the utility and appropriateness of permutation methods in social networks. See these papers for more information: Weiss MN et al. 2021, Common datastream permutations of animal social network data are not appropriate for hypothesis testing using regression models, Methods Ecol Evol Farine DR, 2017, A guide to null models for animal social network analysis, Methods Ecol Evol Hart JDA et al. preprint, Common Permutation Methods in Animal Social Network Analysis Do Not Control for Non-independence Farine DR &amp; Carter GG, preprint, Permutation tests for hypothesis testing with animal social data: problems and potential solutions I will write longer examples of some of the issues raised in these papers soon. First, well discuss some very basic ideas of what permutations can be. 4.1.1 Node Permutation Example Imagine with have a network with 20 individuals. They are split into four different groups. Well label these groups red, blue, yellow and white. ids &lt;- LETTERS[1:20] colors &lt;- c(&quot;red&quot;,&quot;blue&quot;,&quot;yellow&quot;,&quot;white&quot;) names(ids) &lt;- rep(colors, each=5) ids ## red red red red red blue blue blue blue blue yellow ## &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; ## yellow yellow yellow yellow white white white white white ## &quot;L&quot; &quot;M&quot; &quot;N&quot; &quot;O&quot; &quot;P&quot; &quot;Q&quot; &quot;R&quot; &quot;S&quot; &quot;T&quot; We can also store this same data as a data.frame giving each node and its group membership (which well call color). nodes &lt;- data.frame(ids,color = rep(colors, each=5)) nodes ## ids color ## 1 A red ## 2 B red ## 3 C red ## 4 D red ## 5 E red ## 6 F blue ## 7 G blue ## 8 H blue ## 9 I blue ## 10 J blue ## 11 K yellow ## 12 L yellow ## 13 M yellow ## 14 N yellow ## 15 O yellow ## 16 P white ## 17 Q white ## 18 R white ## 19 S white ## 20 T white We are going to simulate some interactions between these individuals. That is, we are going to create an edgelist. The following code produces 50 interactions between pairs of individuals: df &lt;- data.frame(t(replicate(50,sample(LETTERS[1:20],2,F)))) df ## X1 X2 ## 1 B P ## 2 C G ## 3 R N ## 4 P E ## 5 F K ## 6 S E ## 7 F L ## 8 H C ## 9 K B ## 10 F J ## 11 Q O ## 12 A O ## 13 S B ## 14 D E ## 15 A H ## 16 P C ## 17 A E ## 18 A B ## 19 J G ## 20 B K ## 21 G Q ## 22 K J ## 23 S K ## 24 T E ## 25 O T ## 26 E R ## 27 L O ## 28 Q K ## 29 N Q ## 30 Q N ## 31 S T ## 32 G D ## 33 F L ## 34 E H ## 35 B I ## 36 I E ## 37 D O ## 38 Q G ## 39 B K ## 40 A H ## 41 Q L ## 42 M S ## 43 J A ## 44 G H ## 45 A D ## 46 L J ## 47 O L ## 48 L N ## 49 P E ## 50 G T When working with networks in R, we can convert such edgelists into igraph objects using the igraph package. In this example, we shall also add a weight category to each edge (this isnt important for this example, just doing it out of habit), and make the graph undirected. We also simplify the graph: library(igraph) g &lt;- graph_from_data_frame(df) g &lt;- as.undirected(g) g &lt;- simplify(g) g ## IGRAPH 9f1369b UN-- 20 43 -- ## + attr: name (v/c) ## + edges from 9f1369b (vertex names): ## [1] B--P C--P B--S C--H B--K F--K S--K K--Q B--A H--A H--A A--D F--J K--J A--J ## [16] C--G H--G Q--G D--G J--G S--T G--T Q--O A--O D--O T--O R--E P--E S--E H--E ## [31] A--E D--E T--E F--L Q--L J--L O--L R--N Q--N L--N B--I E--I S--M The above output shows the igraph object. Next, we shall use some code to add a color class to each node. We do this by matching the names of the vertices V(g)$name with the names in the nodes data.frame. V(g)$color &lt;- nodes$color[match( V(g)$name, nodes$ids ) ] V(g)$color ## [1] &quot;red&quot; &quot;red&quot; &quot;white&quot; &quot;white&quot; &quot;blue&quot; &quot;white&quot; &quot;blue&quot; &quot;yellow&quot; ## [9] &quot;white&quot; &quot;red&quot; &quot;red&quot; &quot;blue&quot; &quot;blue&quot; &quot;white&quot; &quot;yellow&quot; &quot;red&quot; ## [17] &quot;yellow&quot; &quot;yellow&quot; &quot;blue&quot; &quot;yellow&quot; We can now plot our network by group membership. Each color represents a different group. Our question of interest is Do individuals from the same group show preferential attachment to each other?. plot(g, layout=layout_with_lgl, vertex.label.color=&quot;black&quot;) From the above graph, it looks like perhaps invididual groups are associating preferentially which each other. We can formally measure that by calculating the assortativity. It ranges from -1 to 1. 1 indicates complete association by group membership. 0 indicates no relationship between group membership and association. -1 means that group members preferentially avoid each other. The assortativity function in igraph helps calculate this: ast &lt;- assortativity(g, types1 = as.numeric(factor(V(g)$color)), directed=F) ast ## [1] 0.2073733 How can we test whether this assortativity value of 0.21 is especially high? There are different methods we could employ. We could do a data permutation, where we shuffle the raw data. Alternatively, we could do a node permutation - essentially, we would randomize our group membership. The simplest way to change the group membership would be to permute (shuffle) the node color category and reassign. For example if we do: x &lt;- sample(nodes$color) x ## [1] &quot;blue&quot; &quot;red&quot; &quot;blue&quot; &quot;red&quot; &quot;red&quot; &quot;blue&quot; &quot;white&quot; &quot;white&quot; ## [9] &quot;yellow&quot; &quot;yellow&quot; &quot;red&quot; &quot;white&quot; &quot;yellow&quot; &quot;red&quot; &quot;yellow&quot; &quot;blue&quot; ## [17] &quot;white&quot; &quot;blue&quot; &quot;white&quot; &quot;yellow&quot; We have now fully shuffled the color membership. We could then recalculate the assortativity for this one sample of shuffled group memberships and see if it was higher or lower than our original one. assortativity(g, types1 = as.numeric(factor(x)), directed=F) ## [1] 0.1241303 As we can see, this value is positive but slightly lower than our original value. We could repeat this process many times. Below, I have repeated the process four times and have plotted the resulting networks along with their assortativity: g1&lt;-g par(mfrow = c(2, 2)) par(mar=c(1,1,1,1)) ast.i&lt;-NULL for(i in 1:4){ V(g1)$color &lt;- sample(nodes$color) ast.i &lt;- assortativity(g1, types1 = as.numeric(factor(V(g1)$color)), directed=F) plot(g1, layout=layout_with_lgl, color = V(g1)$color, main = paste0(&quot;Asst = &quot;, round(ast.i,2)), vertex.label.color=&quot;black&quot; ) } Three of these values are negative and one is a small positive. So they are all therefore below our original observed value. We could redo this thousands of times and get a distribution of assortativity values for shuffled (permuted) nodes. Below we do this in a loop 10,000 times: nperms &lt;- 10000 results &lt;- vector(&#39;numeric&#39;,nperms) for(i in 1:nperms){ results[[i]] &lt;- assortativity(g, types1 = as.numeric(factor(sample(V(g)$color)))) } We can plot the distribution of these results and overlay our original assortativity value of 0.21. library(tidyverse) ggplot(data = data.frame(results), aes(x=results)) + geom_histogram(color=&#39;black&#39;,fill=&#39;lightseagreen&#39;, binwidth = 0.02) + theme_classic() + geom_vline(xintercept = ast, lwd=1, lty=2, color=&quot;red&quot;) To compute our p-value, we want to know what proportion of permutations are greater than our observed value. We can calculate that as follows: sum(results&gt;ast)/nperms ## [1] 0.0278 This demonstrates that only 2.78% of permutations (278 out of 10,000) led to assortativity values greater than our observed value. We may conclude from this that our assortativity is significantly positive- suggesting there is a relationship between group membership and network position. i.e. that similar group members are more likely than chance to associate with each other. 4.1.2 Random Graph Approach Another approach that is taken is to compare our observed finding to a distribution of random graphs that have similar properties to our observed graph. The main issue with this approach in animal behavior is that it is incredibly difficult to really produce random graphs that have similar enough properties to our observed data. Therefore the below is just a demonstration of this approach rather than a recommendation. In our observed graph had 20 nodes and 43 undirected edges: g ## IGRAPH 9f1369b UN-- 20 43 -- ## + attr: name (v/c), color (v/c) ## + edges from 9f1369b (vertex names): ## [1] B--P C--P B--S C--H B--K F--K S--K K--Q B--A H--A H--A A--D F--J K--J A--J ## [16] C--G H--G Q--G D--G J--G S--T G--T Q--O A--O D--O T--O R--E P--E S--E H--E ## [31] A--E D--E T--E F--L Q--L J--L O--L R--N Q--N L--N B--I E--I S--M One random graph we could generate is a Erdos-Renyi graph. With this graph we can generate random graphs that contain the same number of nodes and edges as our observed one. r1 &lt;- sample_gnm(n=20, m=43) V(r1)$color &lt;- nodes$color plot(r1, layout=layout_with_lgl, vertex.label.color=&quot;black&quot;) assortativity(r1, types1 = rep(1:4, each=5), directed = FALSE) ## [1] 0.02100692 We can see with our one random Erdos-Renyi graph that the assortativity between nodes and group membership is only 0.02. Again, we could repeat this process for thousands of randomly generated graphs with 20 nodes and 43 edges and observe the distribution: nperms1 &lt;- 10000 results1 &lt;- vector(&#39;numeric&#39;,nperms1) for(i in 1:nperms1){ r &lt;- sample_gnm(n=20, m=43) results1[[i]] &lt;- assortativity(r, types1 = rep(1:4, each=5), directed = FALSE) } We can again plot the distribution of these results and overlay our original assortativity value of 0.2. library(tidyverse) ggplot(data = data.frame(results1), aes(x=results1)) + geom_histogram(color=&#39;black&#39;,fill=&#39;dodgerblue&#39;, binwidth = 0.02) + theme_classic() + geom_vline(xintercept = ast, lwd=1, lty=2, color=&quot;red&quot;) And, again, we can calculate the p-value by determining what proportion of random graphs have values of assortativity greater than our observed value of 0.21 sum(results1&gt;ast)/nperms ## [1] 0.0204 This time our p-value is p=0.0204. So this method gave us a similar p-value to our node permutation method. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
